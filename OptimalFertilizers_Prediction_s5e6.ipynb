{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "data source:\n",
        "* https://www.kaggle.com/competitions/playground-series-s5e6\n",
        "* https://www.kaggle.com/datasets/irakozekelly/fertilizer-prediction"
      ],
      "metadata": {
        "id": "d_nFtFdPgDkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import"
      ],
      "metadata": {
        "id": "N0lf6YzJf798"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install optuna"
      ],
      "metadata": {
        "id": "YbZ1ErcPio5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVmm0O-DdXSu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from numba import cuda\n",
        "\n",
        "if cuda.is_available():\n",
        "  import cupy as cp\n",
        "\n",
        "RANDOM_STATE = 13"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mapk(actual, predicted):\n",
        "    \"\"\"\n",
        "    :actual: np.array([[x], [...]])\n",
        "    :predicted: np.array([[x1, x2, x3, ..., xn], [...]]), indexes of top-N, index equal class label\n",
        "    \"\"\"\n",
        "    matches = (actual == predicted)\n",
        "    matches_index = np.argmax(matches, axis=1)\n",
        "    is_hit = matches.any(axis=1)\n",
        "\n",
        "    return np.mean(np.where(is_hit, 1 / (matches_index+1), 0))\n",
        "\n",
        "\n",
        "def get_metrics(y, y_pred):\n",
        "  return log_loss(y, y_pred), mapk(y, np.argsort(y_pred)[:, -3:][:, ::-1])"
      ],
      "metadata": {
        "id": "kBu5kYcWdgWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv').drop(columns='id')\n",
        "original = pd.read_csv('Fertilizer Prediction.csv')\n",
        "predict = pd.read_csv('test.csv')\n",
        "\n",
        "cols_object = ['Soil Type', 'Crop Type', 'Fertilizer Name'] # train.select_dtypes('object').columns\n",
        "target = 'Fertilizer Name'"
      ],
      "metadata": {
        "id": "5n3mBI4YdgZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoding\n",
        "\n",
        "label_encoder_values = {}\n",
        "label_encoder_values_inverse = {}\n",
        "\n",
        "for col in cols_object:\n",
        "    unique_values = train[col].unique()\n",
        "    encode_values = { val: i for i, val in enumerate(unique_values) }\n",
        "\n",
        "    label_encoder_values[col] = encode_values\n",
        "    label_encoder_values_inverse[col] = dict(zip(encode_values.values(), encode_values.keys()))\n",
        "\n",
        "    train[col] = train[col].map(encode_values)\n",
        "    original[col] = original[col].map(encode_values)\n",
        "\n",
        "    if col != target:\n",
        "        predict[col] = predict[col].map(encode_values)"
      ],
      "metadata": {
        "id": "-dW8MynbgXy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dtype to np.float32\n",
        "\n",
        "for col in train.columns:\n",
        "    train[col] = train[col].astype(np.float32)\n",
        "    original[col] = original[col].astype(np.float32)\n",
        "\n",
        "    if col != target:\n",
        "        predict[col] = predict[col].astype(np.float32)"
      ],
      "metadata": {
        "id": "6rcCNecfgZTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(columns=[target]).values\n",
        "y = train[[target]].values\n",
        "\n",
        "X_original = original.drop(columns=[target]).values\n",
        "y_original = original[[target]].values\n",
        "\n",
        "X_pred = predict.drop(columns=['id']).values\n",
        "y_pred = predict[['id']].copy()"
      ],
      "metadata": {
        "id": "JfNS7o-b2KZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# optuna. base models hyperparameters selection"
      ],
      "metadata": {
        "id": "FweOo3lzgfs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=y, train_size=0.35)"
      ],
      "metadata": {
        "id": "LsHH1qCodgcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, X, y, shuffle=True, random_state=RANDOM_STATE):\n",
        "    params = dict(\n",
        "        max_depth=trial.suggest_int(\"max_depth\", 2, 5),\n",
        "        learning_rate=trial.suggest_float(\"learning_rate\", 0.001, 0.1),\n",
        "        subsample=trial.suggest_float(\"subsample\", 0.7, 0.95),\n",
        "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.4, 0.7),\n",
        "        reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 3.0),\n",
        "        reg_lambda=trial.suggest_float(\"reg_lambda\", 0.5, 5.0),\n",
        "        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 5),\n",
        "        n_estimators=7000,\n",
        "        num_class=7,\n",
        "        objective='multi:softprob',\n",
        "        eval_metric='mlogloss',\n",
        "        booster='gbtree',\n",
        "        tree_method='hist',\n",
        "        device='cuda' if cuda.is_available() else 'cpu',\n",
        "        n_jobs=-1,\n",
        "        early_stopping_rounds=50,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=shuffle, stratify=y, test_size=0.3)\n",
        "\n",
        "    if cuda.is_available(): # CPU -> GPU\n",
        "      X_train, y_train = cp.asarray(X_train), cp.asarray(y_train)\n",
        "      X_val, y_val = cp.asarray(X_val), cp.asarray(y_val)\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
        "    y_val_proba = model.predict_proba(X_val)\n",
        "\n",
        "    if cuda.is_available(): # GPU -> CPU\n",
        "      y_val = y_val.get()\n",
        "\n",
        "    val_logloss, val_mapk = get_metrics(y_val, y_val_proba)\n",
        "\n",
        "    trial.set_user_attr(\"mapk\", val_mapk)\n",
        "\n",
        "    return val_logloss\n",
        "\n",
        "\n",
        "study = optuna.create_study(directions=['minimize'], sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(\n",
        "    lambda trial: objective(trial, X_train, y_train),\n",
        "    n_trials=50,\n",
        "    n_jobs=-1,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "\n",
        "study_result = study.trials_dataframe()\n",
        "study_result_dict = { trial.number: trial.params for trial in study.trials}"
      ],
      "metadata": {
        "id": "wgWSBpSZdgfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study_result.sort_values(by='value', ascending=True).head(5)"
      ],
      "metadata": {
        "id": "RsyJ9AEpdgiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# study_result_dict[]"
      ],
      "metadata": {
        "id": "_beqlgSxdglL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study_result_params = list(study_result.columns[study_result.columns.str.contains('params_')])\n",
        "study_result_params.append('value')\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss_study_result = ss.fit_transform(study_result[study_result_params].values)\n",
        "ss_study_result = pd.DataFrame(ss_study_result, columns=study_result_params)\n",
        "ss_study_result = ss_study_result.join(study_result[['number']], rsuffix='_r').sort_values(by='number', ascending=True)"
      ],
      "metadata": {
        "id": "T2Z-CH5JiGwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "fig, axes = plt.subplots(len(study_result_params[:-1]), 2, figsize=(20,30))\n",
        "\n",
        "for param in study_result_params[:-1]:\n",
        "    if counter == 0:\n",
        "      axes[counter, 0].set_title('Standard Scaled Data')\n",
        "      axes[counter, 1].set_title('Original Data')\n",
        "\n",
        "    sns.lineplot(ax=axes[counter, 0], data=ss_study_result, x='number', y=param, label=param)\n",
        "    sns.lineplot(ax=axes[counter, 0], data=ss_study_result, x='number', y='value', label='value')\n",
        "    axes[counter, 0].grid()\n",
        "    sns.lineplot(ax=axes[counter, 1], data=study_result, x='number', y=param, label=param)\n",
        "    axes[counter, 1].grid()\n",
        "    counter = counter + 1"
      ],
      "metadata": {
        "id": "XPMS6hXfiG2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cross validation score"
      ],
      "metadata": {
        "id": "KDMICuFs0xme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_val_score(model, X, y, X_original=None, y_original=None, n_splits=5, shuffle=True, random_state=RANDOM_STATE):\n",
        "    '''\n",
        "    designed for xgb classifier\n",
        "    :model: xgb classifier\n",
        "    :X, y: np.array\n",
        "    '''\n",
        "\n",
        "    logloss_scores, mapk_scores = list(), list()\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "\n",
        "        print(f'FOLD {fold} running ...')\n",
        "\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        if X_original is not None and y_original is not None:\n",
        "            X_train = np.vstack([X_train, X_original])\n",
        "            y_train = np.vstack([y_train, y_original])\n",
        "\n",
        "        if cuda.is_available(): # CPU -> GPU\n",
        "            X_train, y_train = cp.asarray(X_train), cp.asarray(y_train)\n",
        "            X_val, y_val = cp.asarray(X_val), cp.asarray(y_val)\n",
        "\n",
        "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=1000)\n",
        "        y_val_pred = model.predict_proba(X_val)\n",
        "\n",
        "        if cuda.is_available(): # GPU -> CPU\n",
        "            y_val = y_val.get()\n",
        "\n",
        "        logloss_score, mapk_score = get_metrics(y_val, y_val_pred)\n",
        "        logloss_scores.append(logloss_score)\n",
        "        mapk_scores.append(mapk_score)\n",
        "\n",
        "        print(f'logloss: {logloss_score}, mapk: {mapk_score}')\n",
        "\n",
        "    return np.mean(logloss_scores), np.mean(mapk_scores)"
      ],
      "metadata": {
        "id": "Uq3WlDlyiG9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    # 'max_depth': 8,\n",
        "    # 'learning_rate': 0.027346170065478962,\n",
        "    # 'subsample': 0.9379502039625413,\n",
        "    # 'colsample_bytree': 0.4095558867111752,\n",
        "    # 'reg_alpha': 1.0357095290998455,\n",
        "    # 'reg_lambda': 1.7172337694124145,\n",
        "    # 'min_child_weight': 5,\n",
        "    'max_depth': 12,\n",
        "    'learning_rate': 0.02408978898626546,\n",
        "    'subsample': 0.8722619176156262,\n",
        "    'colsample_bytree': 0.44757526648072804,\n",
        "    'reg_alpha': 2.8463847461990315,\n",
        "    'reg_lambda': 0.6685176738995261,\n",
        "    'min_child_weight': 10,\n",
        "    # --\n",
        "    'n_estimators': 7000,\n",
        "    'num_class': 7,\n",
        "    'objective': 'multi:softprob',\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'booster': 'gbtree',\n",
        "    'tree_method': 'hist',\n",
        "    'device': 'cuda' if cuda.is_available() else 'cpu',\n",
        "    'n_jobs': -1,\n",
        "    'early_stopping_rounds': 100,\n",
        "    'random_state': RANDOM_STATE,\n",
        "}\n",
        "model = XGBClassifier(**params)\n",
        "res = cross_val_score(model=model, X=X, y=y, X_original=X_original, y_original=y_original)"
      ],
      "metadata": {
        "id": "njYSrWIN2Ci1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# stacking"
      ],
      "metadata": {
        "id": "XpJy9Zbo68pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation_stacking(models, X, y, X_pred, X_original=None, y_original=None,\n",
        "                              n_splits=5, shuffle=True, random_state=RANDOM_STATE):\n",
        "\n",
        "    X_folds, y_folds = list(), list()\n",
        "    val_preds = { model: list() for model in models }\n",
        "    pred_preds = { model: np.zeros((X_pred.shape[0], len(np.unique(y)))) for model in models }\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
        "\n",
        "    if cuda.is_available(): # CPU -> GPU\n",
        "        X_pred = cp.asarray(X_pred)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "\n",
        "        print(f'FOLD {fold} running ...')\n",
        "\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        if X_original is not None and y_original is not None:\n",
        "            X_train = np.vstack([X_train, X_original])\n",
        "            y_train = np.vstack([y_train, y_original])\n",
        "\n",
        "        X_folds.append(X_val)\n",
        "        y_folds.append(y_val)\n",
        "\n",
        "        if cuda.is_available(): # CPU -> GPU\n",
        "            X_train, X_val = cp.asarray(X_train), cp.asarray(X_val)\n",
        "            y_train, y_val = cp.asarray(y_train), cp.asarray(y_val)\n",
        "\n",
        "        for model_name, model in models.items():\n",
        "\n",
        "            print(f'MODEL: {model_name}')\n",
        "\n",
        "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
        "            y_train_pred = model.predict_proba(X_train)\n",
        "            y_val_pred = model.predict_proba(X_val)\n",
        "            y_pred = model.predict_proba(X_pred)\n",
        "\n",
        "            val_preds[model_name].append(y_val_pred)\n",
        "            pred_preds[model_name] = pred_preds[model_name] + y_pred\n",
        "\n",
        "            train_logloss, train_mapk = get_metrics(\n",
        "                y_train.get() if cuda.is_available() else y_train, # GPU -> CPU\n",
        "                y_train_pred\n",
        "            )\n",
        "            val_logloss, val_mapk = get_metrics(\n",
        "                y_val.get() if cuda.is_available() else y_val, # GPU -> CPU\n",
        "                y_val_pred\n",
        "            )\n",
        "\n",
        "            print(f'LOGLOSS. Train: {round(train_logloss, 4)} | Val: {round(val_logloss, 4)} | Val to Train: {round(val_logloss/train_logloss, 4)}')\n",
        "            print(f'MAPK.    Train: {round(train_mapk, 4)} | Val: {round(val_mapk, 4)} | Val to Train: {round(val_mapk/train_mapk, 4)}')\n",
        "\n",
        "    pred_preds = { key: (value / n_splits) for key, value in pred_preds.items() }\n",
        "\n",
        "    return X_folds, y_folds, val_preds, pred_preds"
      ],
      "metadata": {
        "id": "lKBQeuEm64Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_params = dict(\n",
        "  n_estimators=7000,\n",
        "  num_class=7,\n",
        "  objective='multi:softprob',\n",
        "  eval_metric='mlogloss',\n",
        "  booster='gbtree',\n",
        "  tree_method='hist',\n",
        "  device='cuda' if cuda.is_available() else 'cpu',\n",
        "  n_jobs=-1,\n",
        "  early_stopping_rounds=100,\n",
        "  random_state=RANDOM_STATE,\n",
        ")\n",
        "\n",
        "params = dict(\n",
        "    xgb01=dict(\n",
        "        max_depth=12,\n",
        "        learning_rate=0.02408978898626546,\n",
        "        subsample=0.8722619176156262,\n",
        "        colsample_bytree=0.44757526648072804,\n",
        "        reg_alpha=2.8463847461990315,\n",
        "        reg_lambda=0.6685176738995261,\n",
        "        min_child_weight=10,\n",
        "    ),\n",
        "    xgb02=dict(\n",
        "        max_depth=11,\n",
        "        learning_rate=0.013600211117010777,\n",
        "        subsample=0.8472484556777177,\n",
        "        colsample_bytree=0.4590701270890474,\n",
        "        reg_alpha=3.3171481083210232,\n",
        "        reg_lambda=0.9381236363848697,\n",
        "        min_child_weight=5,\n",
        "    ),\n",
        "    xgb03=dict(\n",
        "        max_depth=5,\n",
        "        learning_rate=0.07505389046563149,\n",
        "        subsample=0.5259762849436469,\n",
        "        colsample_bytree=0.4524229658909202,\n",
        "        reg_alpha=2.651653141498327,\n",
        "        reg_lambda=4.700559599130367,\n",
        "        min_child_weight=8,\n",
        "    ),\n",
        "    xgb04=dict(\n",
        "        max_depth=8,\n",
        "        learning_rate=0.027346170065478962,\n",
        "        subsample=0.9379502039625413,\n",
        "        colsample_bytree=0.4095558867111752,\n",
        "        reg_alpha=1.0357095290998455,\n",
        "        reg_lambda=1.7172337694124145,\n",
        "        min_child_weight=5,\n",
        "    ),\n",
        "    xgb05=dict(\n",
        "        max_depth=12,\n",
        "        colsample_bytree=0.467,\n",
        "        subsample=0.86,\n",
        "        learning_rate=0.03,\n",
        "        gamma=0.26,\n",
        "        max_delta_step=4,\n",
        "        reg_alpha= 2.7,\n",
        "        reg_lambda= 1.4,\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "for key in params.keys():\n",
        "  params[key].update(base_params)\n",
        "\n",
        "\n",
        "models = { key: XGBClassifier(**value) for key, value in params.items() }"
      ],
      "metadata": {
        "id": "JRjnZqAm64wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = cross_validation_stacking(\n",
        "    models=models,\n",
        "    X=X,\n",
        "    y=y,\n",
        "    X_pred=X_pred,\n",
        "    X_original=X_original,\n",
        "    y_original=y_original\n",
        ")"
      ],
      "metadata": {
        "id": "bZ41MVS664zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_meta_dataset(cv_data):\n",
        "\n",
        "    X_train_fold = np.asarray(cv_data[0]).reshape(-1, 8)\n",
        "    y_train_fold = np.asarray(cv_data[1]).reshape(-1, 1)\n",
        "    X_pred_fold = None\n",
        "\n",
        "    for model_name, model_pred in cv_data[2].items():\n",
        "        X_train_fold = np.hstack((X_train_fold, np.asarray(model_pred).reshape(-1, 7)))\n",
        "\n",
        "        if X_pred_fold is None:\n",
        "          X_pred_fold = cv_data[3][model_name]\n",
        "        else:\n",
        "          X_pred_fold = np.hstack((X_pred_fold, cv_data[3][model_name]))\n",
        "\n",
        "    return X_train_fold, y_train_fold, X_pred_fold\n",
        "\n",
        "\n",
        "X_train_meta, y_train_meta, X_pred_meta = create_meta_dataset(res)"
      ],
      "metadata": {
        "id": "CjoAfCMG642R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to_save = pd.DataFrame(X_train_meta)\n",
        "# to_save.to_csv(url_start+'/X_train_meta.csv', index=False)\n",
        "\n",
        "# to_save = pd.DataFrame(y_train_meta).astype(np.int64).replace(label_encoder_values_inverse['Fertilizer Name'])\n",
        "# to_save.to_csv(url_start+'/y_train_meta.csv', index=False)\n",
        "\n",
        "# to_save = pd.DataFrame(X_test_meta)\n",
        "# to_save.to_csv(url_start+'/X_test_meta.csv', index=False)"
      ],
      "metadata": {
        "id": "7UKsAnvZ2Clm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# optuna. meta-model hyperparameters selection"
      ],
      "metadata": {
        "id": "h7vtYgBp-BiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train_meta[:, 8:],\n",
        "                                                    y_train_meta,\n",
        "                                                    shuffle=True,\n",
        "                                                    stratify=y_train_meta,\n",
        "                                                    train_size=0.4)"
      ],
      "metadata": {
        "id": "PPW5QAkb2Con"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, X, y, shuffle=True):\n",
        "    params = dict(\n",
        "        max_depth=trial.suggest_int(\"max_depth\", 2, 5),\n",
        "        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n",
        "        learning_rate=trial.suggest_float(\"learning_rate\", 0.001, 0.1),\n",
        "        subsample=trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
        "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
        "        gamma=trial.suggest_float('gamma', 0.01, 1.0, log=True),\n",
        "        reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 7.0),\n",
        "        reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 7.0),\n",
        "        # --\n",
        "        n_estimators=7000,\n",
        "        num_class=7,\n",
        "        objective='multi:softprob',\n",
        "        eval_metric='mlogloss',\n",
        "        booster='gbtree',\n",
        "        tree_method='hist',\n",
        "        device='cuda' if cuda.is_available() else 'cpu',\n",
        "        n_jobs=-1,\n",
        "        early_stopping_rounds=100,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=shuffle, stratify=y, test_size=0.3)\n",
        "\n",
        "    if cuda.is_available(): # CPU -> GPU\n",
        "      X_train, y_train = cp.asarray(X_train), cp.asarray(y_train)\n",
        "      X_val, y_val = cp.asarray(X_val), cp.asarray(y_val)\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
        "    y_val_proba = model.predict_proba(X_val)\n",
        "\n",
        "    if cuda.is_available(): # GPU -> CPU\n",
        "      y_val = y_val.get()\n",
        "\n",
        "    val_logloss, val_mapk = get_metrics(y_val, y_val_proba)\n",
        "\n",
        "    trial.set_user_attr(\"mapk\", val_mapk)\n",
        "\n",
        "    return val_logloss\n",
        "\n",
        "\n",
        "study = optuna.create_study(directions=['minimize'], sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(\n",
        "    lambda trial: objective(trial, X_train, y_train),\n",
        "    n_trials=50,\n",
        "    n_jobs=-1,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "\n",
        "study_result = study.trials_dataframe()\n",
        "study_result_dict = { trial.number: trial.params for trial in study.trials}"
      ],
      "metadata": {
        "id": "Y16JcdDV2Crw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study_result.sort_values(by='value').head(5)"
      ],
      "metadata": {
        "id": "uxpHlH9q-jjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# final model. submission"
      ],
      "metadata": {
        "id": "sLy0ipV6-mlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation(X, y, params, X_pred=None, shuffle=True, n_splits=5, random_state=RANDOM_STATE):\n",
        "\n",
        "  y_pred = None\n",
        "  kf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle)\n",
        "\n",
        "  if X_pred is not None:\n",
        "      y_pred = np.zeros(( X_pred.shape[0], len(np.unique(y)) ))\n",
        "\n",
        "      if cuda.is_available():\n",
        "          X_pred = cp.asarray(X_pred)\n",
        "\n",
        "\n",
        "  for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "      X_train, X_val = X[train_idx], X[val_idx]\n",
        "      y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "      if cuda.is_available():\n",
        "          X_train, y_train = cp.asarray(X_train), cp.asarray(y_train)\n",
        "          X_val, y_val = cp.asarray(X_val), cp.asarray(y_val)\n",
        "\n",
        "      model = XGBClassifier(**params)\n",
        "      model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=500)\n",
        "\n",
        "      y_train_pred = model.predict_proba(X_train)\n",
        "      y_val_pred = model.predict_proba(X_val)\n",
        "\n",
        "      if cuda.is_available():\n",
        "          y_train = y_train.get()\n",
        "          y_val = y_val.get()\n",
        "\n",
        "      train_logloss, train_mapk = get_metrics(y_train, y_train_pred)\n",
        "      val_logloss, val_mapk = get_metrics(y_val, y_val_pred)\n",
        "\n",
        "      if X_pred is not None and y_pred is not None:\n",
        "          y_pred = y_pred + model.predict_proba(X_pred)\n",
        "\n",
        "      print(f'LOGLOSS. Train: {round(train_logloss, 4)} | Val: {round(val_logloss, 4)}. V/T: {round(val_logloss/train_logloss, 4)}')\n",
        "      print(f'MAPK@3. Train: {round(train_mapk, 4)} | Val: {round(val_mapk, 4)}. V/T: {round(val_mapk/train_mapk, 4)}')\n",
        "\n",
        "  return (y_pred / n_splits) if y_pred is not None else None"
      ],
      "metadata": {
        "id": "U6jF9OZ1-yX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = cross_validation(\n",
        "    X=X_train_meta[:, 8:],\n",
        "    y=y_train_meta,\n",
        "    X_pred=X_pred_meta,\n",
        "    params={\n",
        "        'max_depth': 3,\n",
        "        'min_child_weight': 1,\n",
        "        'learning_rate': 0.09463613506433619,\n",
        "        'subsample': 0.8783317032856857,\n",
        "        'colsample_bytree': 0.8446428679204586,\n",
        "        'gamma': 0.055331104537748886,\n",
        "        'reg_alpha': 5.100771478049894,\n",
        "        'reg_lambda': 3.516581806624857,\n",
        "        'n_estimators': 7000,\n",
        "        'num_class': 7,\n",
        "        'objective': 'multi:softprob',\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'booster': 'gbtree',\n",
        "        'tree_method': 'hist',\n",
        "        'device': 'cuda' if cuda.is_available() else 'cpu',\n",
        "        'n_jobs': -1,\n",
        "        'early_stopping_rounds': 300,\n",
        "        'random_state': RANDOM_STATE,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "iKy_Hqzu-mDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred.join(pd.DataFrame(np.argsort(res)[:, -3:][:, ::-1]))\n",
        "y_pred[y_pred.columns[1:]] = y_pred[y_pred.columns[1:]].replace(label_encoder_values_inverse['Fertilizer Name'])\n",
        "y_pred['Fertilizer Name'] = y_pred[0] + ' ' + y_pred[1] + ' ' + y_pred[2]\n",
        "y_pred.drop(columns=[0, 1, 2], inplace=True)\n",
        "\n",
        "y_pred.head()"
      ],
      "metadata": {
        "id": "cghvlVLt-rx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "CnkCLE4x-tFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}